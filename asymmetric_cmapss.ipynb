{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env PYTHONHASHSEED=0\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "import math\n",
    "\n",
    "MAXLIFE = 100\n",
    "SCALE = 1\n",
    "RESCALE = 1\n",
    "true_rul = []\n",
    "test_engine_id = 0\n",
    "training_engine_id = 0\n",
    "\n",
    "\n",
    "def kink_RUL(cycle_list, max_cycle):\n",
    "    '''\n",
    "    Piecewise linear function with zero gradient and unit gradient\n",
    "\n",
    "            ^\n",
    "            |\n",
    "    MAXLIFE |-----------\n",
    "            |            \\\n",
    "            |             \\\n",
    "            |              \\\n",
    "            |               \\\n",
    "            |                \\\n",
    "            |----------------------->\n",
    "    '''\n",
    "    knee_point = max_cycle - MAXLIFE\n",
    "    kink_RUL = []\n",
    "    stable_life = MAXLIFE\n",
    "    for i in range(0, len(cycle_list)):\n",
    "        if i < knee_point:\n",
    "            kink_RUL.append(MAXLIFE)\n",
    "        else:\n",
    "            tmp = kink_RUL[i - 1] - (stable_life / (max_cycle - knee_point))\n",
    "            kink_RUL.append(tmp)\n",
    "\n",
    "    return kink_RUL\n",
    "\n",
    "\n",
    "def compute_rul_of_one_id(FD00X_of_one_id, max_cycle_rul=None):\n",
    "    '''\n",
    "    Enter the data of an engine_id of train_FD001 and output the corresponding RUL (remaining life) of these data.\n",
    "    type is list\n",
    "    '''\n",
    "\n",
    "    cycle_list = FD00X_of_one_id['cycle'].tolist()\n",
    "    if max_cycle_rul is None:\n",
    "        max_cycle = max(cycle_list)  # Failure cycle\n",
    "    else:\n",
    "        max_cycle = max(cycle_list) + max_cycle_rul\n",
    "        # print(max(cycle_list), max_cycle_rul)\n",
    "\n",
    "    # return kink_RUL(cycle_list,max_cycle)\n",
    "    return kink_RUL(cycle_list, max_cycle)\n",
    "\n",
    "\n",
    "def compute_rul_of_one_file(FD00X, id='engine_id', RUL_FD00X=None):\n",
    "    '''\n",
    "    Input train_FD001, output a list\n",
    "    '''\n",
    "    rul = []\n",
    "    # In the loop train, each id value of the 'engine_id' column\n",
    "    if RUL_FD00X is None:\n",
    "        for _id in set(FD00X[id]):\n",
    "            rul.extend(compute_rul_of_one_id(FD00X[FD00X[id] == _id]))\n",
    "        return rul\n",
    "    else:\n",
    "        rul = []\n",
    "        for _id in set(FD00X[id]):\n",
    "            # print(\"#### id ####\", int(RUL_FD00X.iloc[_id - 1]))\n",
    "            true_rul.append(int(RUL_FD00X.iloc[_id - 1]))\n",
    "            rul.extend(compute_rul_of_one_id(FD00X[FD00X[id] == _id], int(RUL_FD00X.iloc[_id - 1])))\n",
    "        return rul\n",
    "\n",
    "\n",
    "def get_CMAPSSData(save=False, save_training_data=True, save_testing_data=True, files=[1, 2, 3, 4],\n",
    "                   min_max_norm=False):\n",
    "    '''\n",
    "    :param save: switch to load the already preprocessed data or begin preprocessing of raw data\n",
    "    :param save_training_data: same functionality as 'save' but for training data only\n",
    "    :param save_testing_data: same functionality as 'save' but for testing data only\n",
    "    :param files: to indicate which sub dataset needed to be loaded for operations\n",
    "    :param min_max_norm: switch to enable min-max normalization\n",
    "    :return: function will save the preprocessed training and testing data as numpy objects\n",
    "    '''\n",
    "\n",
    "    if save == False:\n",
    "        return np.load(\"normalized_train_data.npy\"), np.load(\"normalized_test_data.npy\"), pd.read_csv(\n",
    "            'normalized_train_data.csv', index_col=[0]), pd.read_csv('normalized_test_data.csv', index_col=[0])\n",
    "\n",
    "    column_name = ['engine_id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                   's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                   's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "    if save_training_data:  ### Training ###\n",
    "\n",
    "        train_FD001 = pd.read_table(\"train_FD001.txt\", header=None, delim_whitespace=True)\n",
    "        train_FD002 = pd.read_table(\"train_FD002.txt\", header=None, delim_whitespace=True)\n",
    "        train_FD003 = pd.read_table(\"train_FD003.txt\", header=None, delim_whitespace=True)\n",
    "        train_FD004 = pd.read_table(\"train_FD004.txt\", header=None, delim_whitespace=True)\n",
    "        train_FD001.columns = column_name\n",
    "        train_FD002.columns = column_name\n",
    "        train_FD003.columns = column_name\n",
    "        train_FD004.columns = column_name\n",
    "\n",
    "        previous_len = 0\n",
    "        frames = []\n",
    "        for data_file in ['train_FD00' + str(i) for i in files]:  # load subdataset by subdataset\n",
    "\n",
    "            #### standard normalization ####\n",
    "            mean = eval(data_file).iloc[:, 2:len(list(eval(data_file)))].mean()\n",
    "            std = eval(data_file).iloc[:, 2:len(list(eval(data_file)))].std()\n",
    "            std.replace(0, 1, inplace=True)\n",
    "            # print(\"std\", std)\n",
    "            ################################\n",
    "\n",
    "            if min_max_norm:\n",
    "                scaler = MinMaxScaler()\n",
    "                eval(data_file).iloc[:, 2:len(list(eval(data_file)))] = scaler.fit_transform(\n",
    "                    eval(data_file).iloc[:, 2:len(list(eval(data_file)))])\n",
    "            else:\n",
    "                eval(data_file).iloc[:, 2:len(list(eval(data_file)))] = (eval(data_file).iloc[:, 2:len(\n",
    "                    list(eval(data_file)))] - mean) / std\n",
    "\n",
    "            eval(data_file)['RUL'] = compute_rul_of_one_file(eval(data_file))\n",
    "            current_len = len(eval(data_file))\n",
    "            # print(eval(data_file).index)\n",
    "            eval(data_file).index = range(previous_len, previous_len + current_len)\n",
    "            previous_len = previous_len + current_len\n",
    "            # print(eval(data_file).index)\n",
    "            frames.append(eval(data_file))\n",
    "            print(data_file)\n",
    "\n",
    "        train = pd.concat(frames)\n",
    "        global training_engine_id\n",
    "        training_engine_id = train['engine_id']\n",
    "        train = train.drop('engine_id', 1)\n",
    "        train = train.drop('cycle', 1)\n",
    "        # if files[0] == 1 or files[0] == 3:\n",
    "        #     train = train.drop('setting3', 1)\n",
    "        #     train = train.drop('s18', 1)\n",
    "        #     train = train.drop('s19', 1)\n",
    "\n",
    "        train_values = train.values * SCALE\n",
    "        np.save('normalized_train_data.npy', train_values)\n",
    "        train.to_csv('normalized_train_data.csv')\n",
    "        ###########\n",
    "    else:\n",
    "        train = pd.read_csv('normalized_train_data.csv', index_col=[0])\n",
    "        train_values = train.values\n",
    "\n",
    "    if save_testing_data:  ### testing ###\n",
    "\n",
    "        test_FD001 = pd.read_table(\"test_FD001.txt\", header=None, delim_whitespace=True)\n",
    "        test_FD002 = pd.read_table(\"test_FD002.txt\", header=None, delim_whitespace=True)\n",
    "        test_FD003 = pd.read_table(\"test_FD003.txt\", header=None, delim_whitespace=True)\n",
    "        test_FD004 = pd.read_table(\"test_FD004.txt\", header=None, delim_whitespace=True)\n",
    "        test_FD001.columns = column_name\n",
    "        test_FD002.columns = column_name\n",
    "        test_FD003.columns = column_name\n",
    "        test_FD004.columns = column_name\n",
    "\n",
    "        # load RUL data\n",
    "        RUL_FD001 = pd.read_table(\"RUL_FD001.txt\", header=None, delim_whitespace=True)\n",
    "        RUL_FD002 = pd.read_table(\"RUL_FD002.txt\", header=None, delim_whitespace=True)\n",
    "        RUL_FD003 = pd.read_table(\"RUL_FD003.txt\", header=None, delim_whitespace=True)\n",
    "        RUL_FD004 = pd.read_table(\"RUL_FD004.txt\", header=None, delim_whitespace=True)\n",
    "        RUL_FD001.columns = ['RUL']\n",
    "        RUL_FD002.columns = ['RUL']\n",
    "        RUL_FD003.columns = ['RUL']\n",
    "        RUL_FD004.columns = ['RUL']\n",
    "\n",
    "        previous_len = 0\n",
    "        frames = []\n",
    "        for (data_file, rul_file) in [('test_FD00' + str(i), 'RUL_FD00' + str(i)) for i in files]:\n",
    "            mean = eval(data_file).iloc[:, 2:len(list(eval(data_file)))].mean()\n",
    "            std = eval(data_file).iloc[:, 2:len(list(eval(data_file)))].std()\n",
    "            std.replace(0, 1, inplace=True)\n",
    "\n",
    "            if min_max_norm:\n",
    "                scaler = MinMaxScaler()\n",
    "                eval(data_file).iloc[:, 2:len(list(eval(data_file)))] = scaler.fit_transform(\n",
    "                    eval(data_file).iloc[:, 2:len(list(eval(data_file)))])\n",
    "            else:\n",
    "                eval(data_file).iloc[:, 2:len(list(eval(data_file)))] = (eval(data_file).iloc[:, 2:len(\n",
    "                    list(eval(data_file)))] - mean) / std\n",
    "\n",
    "            eval(data_file)['RUL'] = compute_rul_of_one_file(eval(data_file), RUL_FD00X=eval(rul_file))\n",
    "            current_len = len(eval(data_file))\n",
    "            eval(data_file).index = range(previous_len, previous_len + current_len)\n",
    "            previous_len = previous_len + current_len\n",
    "            frames.append(eval(data_file))\n",
    "            print(data_file)\n",
    "            if len(files) == 1:\n",
    "                global test_engine_id\n",
    "                test_engine_id = eval(data_file)['engine_id']\n",
    "\n",
    "        test = pd.concat(frames)\n",
    "        test = test.drop('engine_id', 1)\n",
    "        test = test.drop('cycle', 1)\n",
    "        # if files[0] == 1 or files[0] == 3:\n",
    "        #     test = test.drop('setting3', 1)\n",
    "        #     test = test.drop('s18', 1)\n",
    "        #     test = test.drop('s19', 1)\n",
    "\n",
    "        test_values = test.values * SCALE\n",
    "        np.save('normalized_test_data.npy', test_values)\n",
    "        test.to_csv('normalized_test_data.csv')\n",
    "        ###########\n",
    "    else:\n",
    "        test = pd.read_csv('normalized_test_data.csv', index_col=[0])\n",
    "        test_values = test.values\n",
    "\n",
    "    return train_values, test_values, train, test\n",
    "\n",
    "\n",
    "def get_PHM08Data(save=False):\n",
    "    \"\"\"\n",
    "    Function is to load PHM 2008 challenge dataset\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if save == False:\n",
    "        return np.load(\"./PHM08/processed_data/phm_training_data.npy\"), np.load(\"./PHM08/processed_data/phm_testing_data.npy\"), np.load(\n",
    "            \"./PHM08/processed_data/phm_original_testing_data.npy\")\n",
    "\n",
    "    column_name = ['engine_id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                   's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                   's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "    phm_training_data = pd.read_table(\"./PHM08/train.txt\", header=None, delim_whitespace=True)\n",
    "    phm_training_data.columns = column_name\n",
    "    phm_testing_data = pd.read_table(\"./PHM08/final_test.txt\", header=None, delim_whitespace=True)\n",
    "    phm_testing_data.columns = column_name\n",
    "\n",
    "    print(\"phm training\")\n",
    "    mean = phm_training_data.iloc[:, 2:len(list(phm_training_data))].mean()\n",
    "    std = phm_training_data.iloc[:, 2:len(list(phm_training_data))].std()\n",
    "    phm_training_data.iloc[:, 2:len(list(phm_training_data))] = (phm_training_data.iloc[:, 2:len(\n",
    "        list(phm_training_data))] - mean) / std\n",
    "    phm_training_data['RUL'] = compute_rul_of_one_file(phm_training_data)\n",
    "\n",
    "    print(\"phm testing\")\n",
    "    mean = phm_testing_data.iloc[:, 2:len(list(phm_testing_data))].mean()\n",
    "    std = phm_testing_data.iloc[:, 2:len(list(phm_testing_data))].std()\n",
    "    phm_testing_data.iloc[:, 2:len(list(phm_testing_data))] = (phm_testing_data.iloc[:, 2:len(\n",
    "        list(phm_testing_data))] - mean) / std\n",
    "    phm_testing_data['RUL'] = 0\n",
    "    #phm_testing_data['RUL'] = compute_rul_of_one_file(phm_testing_data)\n",
    "\n",
    "    train_engine_id = phm_training_data['engine_id']\n",
    "    # print(phm_training_engine_id[phm_training_engine_id==1].index)\n",
    "    phm_training_data = phm_training_data.drop('engine_id', 1)\n",
    "    phm_training_data = phm_training_data.drop('cycle', 1)\n",
    "\n",
    "    global test_engine_id\n",
    "    test_engine_id = phm_testing_data['engine_id']\n",
    "    phm_testing_data = phm_testing_data.drop('engine_id', 1)\n",
    "    phm_testing_data = phm_testing_data.drop('cycle', 1)\n",
    "\n",
    "    phm_training_data = phm_training_data.values\n",
    "    phm_testing_data = phm_testing_data.values\n",
    "\n",
    "    engine_ids = train_engine_id.unique()\n",
    "    train_test_split = np.random.rand(len(engine_ids)) < 0.80\n",
    "    train_engine_ids = engine_ids[train_test_split]\n",
    "    test_engine_ids = engine_ids[~train_test_split]\n",
    "\n",
    "    # test_engine_id = pd.Series(test_engine_ids)\n",
    "\n",
    "\n",
    "    training_data = phm_training_data[train_engine_id[train_engine_id == train_engine_ids[0]].index]\n",
    "    for id in train_engine_ids[1:]:\n",
    "        tmp = phm_training_data[train_engine_id[train_engine_id == id].index]\n",
    "        training_data = np.concatenate((training_data, tmp))\n",
    "    # print(training_data.shape)\n",
    "\n",
    "    testing_data = phm_training_data[train_engine_id[train_engine_id == test_engine_ids[0]].index]\n",
    "    for id in test_engine_ids[1:]:\n",
    "        tmp = phm_training_data[train_engine_id[train_engine_id == id].index]\n",
    "        testing_data = np.concatenate((testing_data, tmp))\n",
    "    # print(testing_data.shape)\n",
    "\n",
    "    print(phm_training_data.shape, phm_testing_data.shape, training_data.shape, testing_data.shape)\n",
    "\n",
    "    np.save(\"./PHM08/processed_data/phm_training_data.npy\", training_data)\n",
    "    np.savetxt(\"./PHM08/processed_data/phm_training_data.txt\", training_data, delimiter=\" \")\n",
    "    np.save(\"./PHM08/processed_data/phm_testing_data.npy\", testing_data)\n",
    "    np.savetxt(\"./PHM08/processed_data/phm_testing_data.txt\", testing_data, delimiter=\" \")\n",
    "    np.save(\"./PHM08/processed_data/phm_original_testing_data.npy\", phm_testing_data)\n",
    "    np.savetxt(\"./PHM08/processed_data/phm_original_testing_data.csv\", phm_testing_data, delimiter=\",\")\n",
    "\n",
    "    return training_data, testing_data, phm_testing_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data, training_pd, testing_pd = get_CMAPSSData(save=True, min_max_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FD001_TRAIN_LENGTH = 20631\n",
    "#FD001_TRAIN_LENGTH = 61042\n",
    "FD002_TRAIN_LENGTH = 53759\n",
    "FD003_TRAIN_LENGTH = 24720\n",
    "FD004_TRAIN_LENGTH = 61249\n",
    "\n",
    "FD_001_train_data = training_data[0:FD001_TRAIN_LENGTH][:]\n",
    "#Remove column that are constant \n",
    "FD_001_train_data = np.delete(FD_001_train_data, [2,3, 7, 8, 12, 18, 20, 21], 1)\n",
    "FD_001_X_train = FD_001_train_data[:, 0:-1]\n",
    "FD_001_Y_train = FD_001_train_data[:, -1]\n",
    "\n",
    "# Split into train-validation 90/10 ratio\n",
    "X_train = FD_001_X_train[0:math.ceil(FD001_TRAIN_LENGTH*0.9)]\n",
    "X_val = FD_001_X_train[math.ceil(FD001_TRAIN_LENGTH*0.9):]\n",
    "\n",
    "y_train = FD_001_Y_train[0:math.ceil(FD001_TRAIN_LENGTH*0.9)]\n",
    "y_val = FD_001_Y_train[math.ceil(FD001_TRAIN_LENGTH*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FD001_TEST_LENGTH = 13096\n",
    "FD002_TEST_LENGTH = 33991\n",
    "FD003_TEST_LENGTH = 16596\n",
    "FD004_TEST_LENGTH = 41214\n",
    "\n",
    "FD_001_test_data = testing_data[0:FD001_TEST_LENGTH][:]\n",
    "#Remove column that are constant \n",
    "FD_001_test_data = np.delete(FD_001_test_data, [2,3, 7, 8, 12, 18, 20, 21], 1)\n",
    "X_test = FD_001_test_data[:, 0:-1]\n",
    "y_test = FD_001_test_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "\n",
    "window_size = 30\n",
    "\n",
    "train_data = TimeseriesGenerator(X_train, y_train,\n",
    "                               length=window_size, sampling_rate=1,\n",
    "                               batch_size=window_size)\n",
    "\n",
    "val_data = TimeseriesGenerator(X_val, y_val,\n",
    "                               length=window_size, sampling_rate=1,\n",
    "                               batch_size=window_size)\n",
    "\n",
    "test_data = TimeseriesGenerator(X_test, y_test,\n",
    "                               length=window_size, sampling_rate=1,\n",
    "                               batch_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y=train_data[0]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation of Deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
    "\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = FD_001_X_train.shape[1]\n",
    "nb_out = 1\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "#Bi-directional LSTM\n",
    "\n",
    "# model.add(Bidirectional(layers.LSTM(units=50, return_sequences=True),input_shape=(window_size, nb_features)))\n",
    "# model.add(Bidirectional(layers.LSTM(units=25)))\n",
    "# model.add(layers.Dense(units=50))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Activation(\"relu\"))\n",
    "# model.add(layers.Dense(units=nb_out))\n",
    "# model.add(layers.Activation(\"relu\"))\n",
    "\n",
    "#CNN1D\n",
    "model.add(layers.Conv1D(60,2, activation='relu', data_format='channels_last', input_shape=(window_size, nb_features)))\n",
    "model.add(layers.Conv1D(60,2, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(nb_out, activation='relu'))\n",
    "\n",
    "# #basic dnn\n",
    "# model.add(layers.Dense(100, input_shape=(window_size, nb_features), kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(layers.Dense(250, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(layers.Dense(12, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(layers.Dense(6, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(layers.Dense(4, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dropout(0.2))\n",
    "# model.add(layers.Dense(nb_out, activation='relu'))\n",
    "\n",
    "\n",
    "#GRU\n",
    "# model.add(Bidirectional(GRU(units=100,return_sequences=True),input_shape=(window_size, nb_features)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Bidirectional(GRU(units=50)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(units=20))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# #model.add(LeakyReLU(alpha=0.3))\n",
    "# model.add(Dense(units=nb_out))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# #model.add(LeakyReLU(alpha=0.3))\n",
    "# model.add(Dense(nb_out, activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Custom loss functions and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "############# custom loss #################\n",
    "###########################################\n",
    "def msle_mse(y_true, y_pred):\n",
    "    w = K.switch(\n",
    "        K.less(K.sum(K.mean(y_pred, axis=0))-K.sum(K.mean(y_true, axis=0)), 0),\n",
    "        K.sum(K.mean(K.square(K.log(y_true+1)-K.log(y_pred+1)), axis=0)),\n",
    "        K.sum(K.mean(K.square(y_true-y_pred), axis=0))\n",
    "    )\n",
    "    return w\n",
    "\n",
    "def mse_mse(y_true, y_pred):\n",
    "    w = K.switch(\n",
    "        K.less(K.sum(K.mean(y_pred))-K.sum(K.mean(y_true)), 0),\n",
    "        K.sum(K.mean(K.square(y_true-y_pred))),\n",
    "        K.sum(K.mean(K.square(y_true-y_pred)))\n",
    "    )\n",
    "    return w\n",
    "\n",
    "def msle_msle(y_true, y_pred):\n",
    "    w = K.switch(\n",
    "        K.less(K.sum(K.mean(y_pred))-K.sum(K.mean(y_true)), 0),\n",
    "        K.mean(K.sum(K.square(K.log(y_true+1)-K.log(y_pred+1)))),\n",
    "        K.mean(K.sum(K.square(K.log(y_true+1)-K.log(y_pred+1))))\n",
    "    )\n",
    "    return w\n",
    "\n",
    "def mae_mae(y_true, y_pred):\n",
    "    w = K.switch(\n",
    "        K.less(K.sum(K.mean(y_pred))-K.sum(K.mean(y_true)), 0),\n",
    "        K.sum(K.mean(K.abs(y_true-y_pred))),\n",
    "        K.sum(K.mean(K.abs(y_true-y_pred)))\n",
    "    )\n",
    "    return w\n",
    "\n",
    "def lin_mse(y_true, y_pred):\n",
    "    a = 0.5\n",
    "    w = K.switch(\n",
    "        K.less(K.sum(K.mean(y_pred-y_true)), 0),\n",
    "        -a*(K.sum(K.mean(y_pred-y_true))),\n",
    "        K.sum(K.mean(K.square(y_true-y_pred), axis=0))\n",
    "    )\n",
    "    return w\n",
    "\n",
    "def lin_lin(y_true, y_pred):\n",
    "    a = 2\n",
    "    c = 6\n",
    "    w = K.switch(\n",
    "        K.less(K.sum(K.mean(y_pred-y_true)), 0),\n",
    "        -a*(K.sum(K.mean(y_pred-y_true))),\n",
    "        c*(K.sum(K.mean(y_pred-y_true)))\n",
    "    )\n",
    "    return w\n",
    "\n",
    "def quad_quad(y_true, y_pred):\n",
    "    a = 0.3\n",
    "    w = K.switch(\n",
    "        K.less(K.sum(K.mean(y_pred-y_true)), 0),\n",
    "        (K.sum(K.mean(2*(a)*K.square(y_pred-y_true)))),\n",
    "        (K.sum(K.mean(2*(a+(1-(2*a)))*K.square(y_pred-y_true))))\n",
    "    )\n",
    "    return w\n",
    "\n",
    "\n",
    "###########################################\n",
    "############# custom metrics ##############\n",
    "###########################################\n",
    "\n",
    "def SF(y_true, y_pred):\n",
    "    s = K.switch(\n",
    "        K.less(K.sum(y_pred-y_true), 0),\n",
    "        K.sum(K.exp((-(y_pred-y_true)/13))-1),\n",
    "        K.sum(K.exp(((y_pred-y_true)/10))-1)\n",
    "    )\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=quad_quad, optimizer='nadam' ,metrics=[SF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define path to save model\n",
    "model_path = 'lstm_regression__cmapss_model.h5'\n",
    "\n",
    "#reduce_lr_loss = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_SF', min_delta=0, patience=50, verbose=0, mode='min', restore_best_weights=True)\n",
    "mcp_save = keras.callbacks.ModelCheckpoint(model_path,monitor='val_SF', save_best_only=True, mode='min', verbose=0)\n",
    "\n",
    "# fit the network\n",
    "import time\n",
    "start=time.time()\n",
    "history = model.fit_generator(train_data, epochs=1000, validation_data=val_data, verbose=1, shuffle=False,\n",
    "          callbacks = [earlyStopping, mcp_save]\n",
    "          )\n",
    "end=time.time()\n",
    "print('Total Training Time: ', end-start)\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for validation score\n",
    "fig_acc = plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['SF'])\n",
    "plt.plot(history.history['val_SF'])\n",
    "plt.title('model SF')\n",
    "plt.ylabel('SF')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test metrics\n",
    "scores_test = model.evaluate_generator(test_data, verbose=2)\n",
    "print('\\nSF: {}'.format(scores_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_generator(test_data)\n",
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get y from generator data\n",
    "def get_y_from_generator(gen):\n",
    "    '''\n",
    "    Get all targets y from a TimeseriesGenerator instance.\n",
    "    '''\n",
    "    y = None\n",
    "    for i in range(len(gen)):\n",
    "        batch_y = gen[i][1]\n",
    "        if y is None:\n",
    "            y = batch_y\n",
    "        else:\n",
    "            y = np.append(y, batch_y)\n",
    "    y = y.reshape((-1,1))\n",
    "    print(y.shape)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = get_y_from_generator(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of final actual and predicted RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot in blue color the predicted data and in green color the\n",
    "# actual data to verify visually the accuracy of the model.\n",
    "fig_verify = plt.figure(figsize=(20, 10))\n",
    "plt.plot(predict[0:1000], color=\"blue\")\n",
    "plt.plot(actual[0:1000], color=\"green\")\n",
    "plt.title('prediction')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('row')\n",
    "plt.legend(['predicted', 'actual data'], loc='upper left')\n",
    "plt.show()\n",
    "fig_verify.savefig(\"model_CNN1D_verify.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the scoring function\n",
    "\n",
    "def scoring_function(true, pred):\n",
    "    d = pred - true\n",
    "    length = len(d)\n",
    "    s = 0\n",
    "    num = []\n",
    "    for i in range(length):\n",
    "        if(i != length-1 and true[i]-true[i+1]<0):\n",
    "            if (d[i] < 0):\n",
    "                s += np.exp((-d[i]/13))-1\n",
    "            else:\n",
    "                s += np.exp((d[i]/10))-1\n",
    "            num.append(i)\n",
    "    return s, num\n",
    "\n",
    "def rmse(true, pred):\n",
    "    d_squared = (pred - true)**2\n",
    "    length = len(d_squared)\n",
    "    err = 0\n",
    "    for i in range(length):\n",
    "        err += d_squared[i]\n",
    "    err = np.sqrt(err/length)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Result of Score and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf, num = scoring_function(actual,predict)\n",
    "rmse_err = rmse(actual,predict)\n",
    "print(sf,rmse_err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
